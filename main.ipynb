{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMU Data Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Data processing\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import svm\n",
    "\n",
    "# Helper functions\n",
    "from helper.helper_filter import *\n",
    "from helper.helper_preprocess import *\n",
    "from helper.helper_train import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the raw data from each target action and store them in a list\n",
    "lqw_raw = load_data(\"./IMU_Data/LGW\")\n",
    "ramp_ascend_raw = load_data(\"./IMU_Data/Ramp_ascend\")\n",
    "ramp_descend_raw = load_data(\"./IMU_Data/Ramp_descend\")\n",
    "sit_to_stand_raw = load_data(\"./IMU_Data/Sit_to_stand\")\n",
    "stand_to_sit_raw = load_data(\"./IMU_Data/Stand_to_sit\")\n",
    "\n",
    "folders = [lqw_raw, ramp_ascend_raw, ramp_descend_raw, sit_to_stand_raw, stand_to_sit_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all columns that contain sync, annotations and offset timestamps\n",
    "for folder in folders:\n",
    "    for file in folder:\n",
    "        # Drop all columns that contain sync, annotations and offset timestamps\n",
    "        file.data_filtered.drop(columns=[col for col in file.data_filtered.columns if \n",
    "                                any(info in col.lower() for info in [\"sync\", \"offset\", \"annotation\"])], inplace=True)\n",
    "        \n",
    "        # Drop all timestamp columns that are not \"Shank_L_Timestamp\"\n",
    "        for column in file.data_filtered.columns:\n",
    "            if \"timestamp\" in column.lower():\n",
    "                if column.lower() != \"shank_l_timestamp\":\n",
    "                    file.data_filtered.drop(columns=column, inplace=True)\n",
    "        \n",
    "        # Replace column name and place as the first index \n",
    "        file.data_filtered.rename(columns={'Shank_L_Timestamp': 'Timestamp'}, inplace=True)\n",
    "        col = file.data_filtered.pop('Timestamp')\n",
    "        file.data_filtered.insert(0, col.name, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values with the k-Nearest Neighbor\n",
    "for folder in folders:\n",
    "    for file in folder:\n",
    "        if file.data_filtered.isnull().sum().sum() > 0:\n",
    "            imputer = KNNImputer(n_neighbors=5)\n",
    "            file.data_filtered = pd.DataFrame(imputer.fit_transform(file.data_filtered), \n",
    "                                              columns = file.data_filtered.columns)\n",
    "            \n",
    "# Check if any NaN values are left\n",
    "for folder in folders:\n",
    "    for file in folder:\n",
    "        if file.data_filtered.isnull().sum().sum() > 0: \n",
    "            print(\"NaN values left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers and smooth curve using a low pass filter\n",
    "for folder in folders:\n",
    "    for file in folder:\n",
    "        # Extract sampling time\n",
    "        ts = file.data_filtered[\"Timestamp\"].diff().median() # Median sampling time\n",
    "\n",
    "        # Remove outliers\n",
    "        for name, data in file.data_filtered.items():\n",
    "            if name != 'Timestamp':\n",
    "                data = low_pass_filter(ts, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the slinding window technique\n",
    "tw = 350        # window size\n",
    "dt = 50         # window step\n",
    "\n",
    "# Apply the moving average filter to the data and get all features\n",
    "for folder in folders:\n",
    "    for file in folder:\n",
    "        # Apply the slinding window to the data\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "            file.data_processed = generate_features(file.data_filtered, tw, dt)\n",
    "\n",
    "        # Drop first row where the gradient is 0\n",
    "        file.data_processed = file.data_processed.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all five actions into one dataframe and set the target labels using one-hot encoding \n",
    "iterator = 1\n",
    "all_df = []\n",
    "\n",
    "for folder in folders:    \n",
    "    # Create single dataframe for action\n",
    "    df = pd.DataFrame()\n",
    "    df = pd.concat([file.data_processed for file in folder[:2]])\n",
    "\n",
    "    # Add target labels\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "        df[\"Action\"] = iterator\n",
    "        iterator = iterator + 1\n",
    "    \n",
    "    # Add dataframe to the list\n",
    "    all_df.append(df)\n",
    "\n",
    "# Combine all dataframes into one\n",
    "df = pd.concat(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"combined_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X = df.iloc[:, :-1]     # Input features\n",
    "y = df.iloc[:, -1:]     # Target labels\n",
    "\n",
    "# Split data into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=109) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1617: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8329466357308585\n",
      "Precision:  0.8826694820697644\n",
      "Recall:  0.8329466357308585\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.93      0.83      0.87       179\n",
      "           2       0.72      0.85      0.78        85\n",
      "           3       0.93      0.78      0.85        82\n",
      "           4       0.86      0.98      0.91        44\n",
      "           5       0.97      0.78      0.86        41\n",
      "           6       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.83       431\n",
      "   macro avg       0.63      0.60      0.61       431\n",
      "weighted avg       0.88      0.83      0.85       431\n",
      "\n",
      "[[  0   0   0   0   0   0   0]\n",
      " [ 16 148  14   1   0   0   0]\n",
      " [  0  10  72   3   0   0   0]\n",
      " [  0   2  14  64   1   1   0]\n",
      " [  0   0   0   1  43   0   0]\n",
      " [  0   0   0   0   6  32   3]\n",
      " [  0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# ANN\n",
    "ann_model = MLPRegressor(hidden_layer_sizes=(10, 5), \n",
    "                     activation=\"relu\" ,\n",
    "                     random_state=42, max_iter=2000)\n",
    "\n",
    "ann_model.fit(X_train, y_train)\n",
    "ann_pred = ann_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "get_metrics(y_test, ann_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9791183294663574\n",
      "Precision:  0.9794966205992132\n",
      "Recall:  0.9791183294663574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.99      0.98       179\n",
      "           2       0.96      0.96      0.96        85\n",
      "           3       1.00      0.95      0.97        82\n",
      "           4       1.00      1.00      1.00        44\n",
      "           5       1.00      0.98      0.99        41\n",
      "\n",
      "    accuracy                           0.98       431\n",
      "   macro avg       0.99      0.98      0.98       431\n",
      "weighted avg       0.98      0.98      0.98       431\n",
      "\n",
      "[[178   1   0   0   0]\n",
      " [  3  82   0   0   0]\n",
      " [  3   1  78   0   0]\n",
      " [  0   0   0  44   0]\n",
      " [  0   1   0   0  40]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "# Create a svm Classifier\n",
    "svm_model = svm.SVC(kernel='linear') # Linear Kernel\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "get_metrics(y_test, svm_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
