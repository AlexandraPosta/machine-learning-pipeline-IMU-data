{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMU Data Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "import seaborn as sns\n",
    "import dataframe_image as dfi\n",
    "import warnings\n",
    "\n",
    "# Statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data processing\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Machine learning/Deep learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import TensorBoard, ReduceLROnPlateau\n",
    "\n",
    "# Helper functions\n",
    "from helper.helper_filter import *\n",
    "from helper.helper_preprocess import *\n",
    "from helper.helper_train import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter data\n",
    "### Extract data tables and visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the raw data from each target action and store them in a list\n",
    "lqw_raw = load_data(\"./IMU_Data/LGW\")\n",
    "ramp_ascend_raw = load_data(\"./IMU_Data/Ramp_ascend\")\n",
    "ramp_descend_raw = load_data(\"./IMU_Data/Ramp_descend\")\n",
    "sit_to_stand_raw = load_data(\"./IMU_Data/Sit_to_stand\")\n",
    "stand_to_sit_raw = load_data(\"./IMU_Data/Stand_to_sit\")\n",
    "\n",
    "folders = [lqw_raw, ramp_ascend_raw, ramp_descend_raw, sit_to_stand_raw, stand_to_sit_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview some of the data to check format\n",
    "lqw_raw[0].data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lqw_raw[0].data.head()\n",
    "dfi.export(lqw_raw[0].data, \"assets/table_1.png\", max_rows=10, max_cols=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms to visualize all data\n",
    "lqw_raw[0].data.hist(bins=50,figsize=(30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check entries that are outside of the standard deviation\n",
    "std_table = []\n",
    "head = [\"Action\",\"File name\", \"Column name\", \"Mean\", \"Standard deviation\", \"#entries>5std\", \"#entries<5std\"]\n",
    "\n",
    "for folder in folders:\n",
    "    for file in folder:\n",
    "        for column in file.data:\n",
    "            mean = file.data[column].mean()\n",
    "            std = file.data[column].std()\n",
    "            count_above_std5 = 0\n",
    "            count_below_std5 = 0\n",
    "\n",
    "            for entry in file.data[column]:\n",
    "                if entry < mean - std*5:\n",
    "                    count_below_std5 += 1\n",
    "                elif entry > mean + std*5:\n",
    "                    count_above_std5 += 1\n",
    "\n",
    "            if count_above_std5 > 0 or count_below_std5 > 0:\n",
    "                std_table.append([file.folder_name, file.file_name, column, format(mean, '.4f'), format(std, '.4f'), count_above_std5, count_below_std5]) # add data for every column\n",
    "\n",
    "print(tabulate(std_table, headers=head, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for unwanted columns\n",
    "From the table above, we can see how multiple timestamps have been used across different files. It was decided to investigate further whether the timestamps are aligned and can be ignored. It can be seen how, under the LGW some files are missing \"Sync\" and \"Offset\" timestamp, so it was decided to remove all columns that contains them to ensure consistency across the data. Additionally, the LWR from SV misses the timestamp from the Right sensors and Thigh. The timestamps that appear across al columns are 'Shank_L_Timestamp', 'Foot_L_Timestamp', 'Pelvis_Timestamp', arguebly one of them should be used as the baseline time.\n",
    "\n",
    "The total number of entries is plotted as well, it can be seen how the majority of the data comes from the ground walking action and less from the standing and sitting actions. This might result in a bias towards the former action mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of columns in each dataframe\n",
    "column_table = []\n",
    "head = [\"Action\",\"File name\", \"Row Nr\", \"Column Nr\", \"Timestamp columns\"]\n",
    "df_table = pd.DataFrame(columns=[\"Action\",\"File name\", \"Row Nr\", \"Column Nr\", \"Timestamp columns\"])\n",
    "\n",
    "for folder in folders:\n",
    "    for file in folder:\n",
    "        filtered_columns =[col for col in file.data.columns if \"timestamp\" in col.lower()]\n",
    "        column_table.append([file.folder_name, file.file_name, file.data.index.size, len(file.data.columns), filtered_columns])\n",
    "        df_table.loc[len(df_table)] = [file.folder_name, file.file_name, file.data.index.size, len(file.data.columns), filtered_columns]\n",
    "        style = df_table.style.set_properties(subset=['Timestamp columns'], **{'width': '500px'})\n",
    "\n",
    "table = tabulate(column_table, headers=head, tablefmt='grid')\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi.export(style, \"assets/table_2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all timestamps columns have the same data inside a dataframe and check what is the difference in time between them\n",
    "reference_columns = ['Shank_L_Timestamp', 'Foot_L_Timestamp', 'Pelvis_Timestamp']\n",
    "\n",
    "for folder in folders:\n",
    "    for file in folder[:2]:\n",
    "        for ref in reference_columns:\n",
    "            # Filter columns to get only those containing time\n",
    "            time_columns = [col for col in file.data_filtered.columns if 'timestamp' in col.lower()]\n",
    "\n",
    "            # Reference column for comparison\n",
    "            ref_column = file.data_filtered[ref]\n",
    "            time_difference = []\n",
    "            for col in time_columns:\n",
    "                time_difference.append(file.data_filtered[col] - ref_column)\n",
    "\n",
    "            means = [sum(inner_array)/len(inner_array) for inner_array in time_difference]\n",
    "            if max(means) > 1000.: # if difference is bigger than 1 seconds\n",
    "                print(f\"Using {ref} - Different timestamp in {file.file_name} with maximum value: {format(max(means), '.3f')}\")\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all columns that contain sync, annotations and offset timestamps\n",
    "for folder in folders:\n",
    "    for file in folder:\n",
    "        # Drop all columns that contain sync, annotations and offset timestamps\n",
    "        file.data_filtered.drop(columns=[col for col in file.data_filtered.columns if \n",
    "                                any(info in col.lower() for info in [\"sync\", \"offset\", \"annotation\"])], inplace=True)\n",
    "        \n",
    "        # Drop all timestamp columns that are not \"Shank_L_Timestamp\"\n",
    "        for column in file.data_filtered.columns:\n",
    "            if \"timestamp\" in column.lower():\n",
    "                if column.lower() != \"shank_l_timestamp\":\n",
    "                    file.data_filtered.drop(columns=column, inplace=True)\n",
    "        \n",
    "        # Replace column name and place as the first index \n",
    "        file.data_filtered.rename(columns={'Shank_L_Timestamp': 'Timestamp'}, inplace=True)\n",
    "        col = file.data_filtered.pop('Timestamp')\n",
    "        file.data_filtered.insert(0, col.name, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of columns in each dataframe\n",
    "column_table = []\n",
    "head = [\"Action\",\"File name\", \"Row Nr\", \"Column Nr\"]\n",
    "\n",
    "for folder in folders:\n",
    "    for file in folder:\n",
    "        column_table.append([file.folder_name, file.file_name, file.data.index.size, len(file.data.columns)])\n",
    "\n",
    "print(tabulate(column_table, headers=head, tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for NaNs\n",
    "It can be observed how the only files that contains NaNs are normal_walk_lg_trial_01.dat and normal_walk_lg_trial_02.dat. Both files contain 1521 entry with 17 or 56 NaN entries in individual columns. The NaN values constitute 1.12% and 3.68%, respectively of the total entries. A nearest neighbors imputation strategy is used to replace the missing data from the set. Originally, a simple imputation was used with a \"median\" strategy, but, after checking the data, all of the features that need imputation are Gaussian distributed (except the Pelvic magnometometer data that has two peaks). It is better to replace the missing data with a Gaussian distributed set of values compared to a constant. k-Nearest Neighbors offers the advantage of tuning the missing values by using the neighboring entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of columns in each dataframe\n",
    "nan_table = []\n",
    "head = [\"Action\",\"File name\", \"NaN total number\", \"NaN columns\"]\n",
    "columns_to_visualize = []\n",
    "df_table = pd.DataFrame(columns=[\"Action\",\"File name\", \"NaN total number\", \"NaN columns\"])\n",
    "\n",
    "for folder in folders:\n",
    "    for file in folder:\n",
    "        nan_number = file.data_filtered.isnull().sum().sum()\n",
    "        \n",
    "        # Add to table only if there are NaN values\n",
    "        if nan_number > 0:\n",
    "            nan_columns = \"\"\n",
    "            nan = \"\"\n",
    "            columns_to_visualize.append(file.data_filtered)\n",
    "            \n",
    "            # Check which columns have NaN values and how many\n",
    "            for col in file.data_filtered.columns:\n",
    "                if file.data_filtered[col].isnull().sum() > 0:\n",
    "                    nan_columns += col + \"=\" + str(file.data_filtered[col].isnull().sum()) + \"\\n\"\n",
    "                    nan += col + \"=\" + str(file.data_filtered[col].isnull().sum()) + \", \"\n",
    "            \n",
    "            nan_table.append([file.folder_name, file.file_name, nan_number, nan_columns])\n",
    "            df_table.loc[len(df_table)] = [file.folder_name, file.file_name, nan_number, nan]\n",
    "\n",
    "print(tabulate(nan_table, headers=head, tablefmt='grid'))\n",
    "\n",
    "style = df_table.style.set_properties(subset=['NaN columns'], **{'width': '500px'})\n",
    "dfi.export(style, \"assets/table_3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms to visualize all data\n",
    "for visualize in columns_to_visualize:\n",
    "    visualize.hist(bins=50,figsize=(30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values with the k-Nearest Neighbor\n",
    "for folder in folders:\n",
    "    for file in folder:\n",
    "        if file.data_filtered.isnull().sum().sum() > 0:\n",
    "            imputer = KNNImputer(n_neighbors=5)\n",
    "            file.data_filtered = pd.DataFrame(imputer.fit_transform(file.data_filtered),columns = file.data_filtered.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any NaN values are left\n",
    "for folder in folders:\n",
    "    for file in folder:\n",
    "        if file.data_filtered.isnull().sum().sum() > 0: \n",
    "            print(\"NaN values left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "### Apply filtering\n",
    "Check IMU data against vibrations; accelerometer may record high frequency noise due to vibration. It was calculated that the sampling time is about 9.8 miliseconds, frequency of about 102.4Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the filter and find appropriate parameters\n",
    "data = folder[0].data_filtered\n",
    "old_data = folder[0].data[\"Thigh_R_Gyroscope_Y\"]\n",
    "new_data = None\n",
    "\n",
    "# Sampling frequency\n",
    "ts = data[\"Timestamp\"].diff().median()  # Sampling time\n",
    "fs = 1000/ts                            # Sampling frequency\n",
    "\n",
    "# Filter design\n",
    "N = 3               # Order of the filter \n",
    "cutoff = 25.0       # Cutoff frequency\n",
    "\n",
    "# Apply filter\n",
    "new_data = low_pass_filter(ts, old_data)\n",
    "\n",
    "# Plot the original and filtered signals\n",
    "plt.figure(figsize=(15, 8))\n",
    "start = 0\n",
    "end = 500\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(data[\"Timestamp\"][start:end], old_data[start:end])\n",
    "plt.title('Original Signal', fontsize=20)\n",
    "plt.xlabel('Time [s]', fontsize=16)\n",
    "plt.ylabel('Amplitude', fontsize=16)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(data[\"Timestamp\"][start:end], new_data[start:end])\n",
    "plt.title('Filtered Signal (Low-pass Filter)', fontsize=20)\n",
    "plt.xlabel('Time [s]', fontsize=16)\n",
    "plt.ylabel('Amplitude' , fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers and smooth curve using a low pass filter\n",
    "for folder in folders:\n",
    "    for file in folder:\n",
    "        # Extract sampling time\n",
    "        ts = file.data_filtered[\"Timestamp\"].diff().median() # Median sampling time\n",
    "\n",
    "        # Remove outliers\n",
    "        for name, data in file.data_filtered.items():\n",
    "            if name != 'Timestamp':\n",
    "                data = low_pass_filter(ts, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the slinding window technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if technique works\n",
    "tw = 350    # window size\n",
    "dt = 50     # time increment\n",
    "\n",
    "test = folder[0].data_filtered\n",
    "output = pd.DataFrame()\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "    output = generate_features(test, tw, dt)\n",
    "\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = 350        # window size\n",
    "dt = 50         # window step\n",
    "\n",
    "# Apply the moving average filter to the data and get all features\n",
    "# Takes around 30 minutes to run\n",
    "for folder in folders:\n",
    "    for file in folder:\n",
    "        # Apply the slinding window to the data\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "            file.data_processed = generate_features(file.data_filtered, tw, dt)\n",
    "\n",
    "        # Drop first row where the gradient is 0\n",
    "        file.data_processed = file.data_processed.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if technique works\n",
    "dfi.export(file.data_processed, \"assets/table_4.png\", max_rows=10, max_cols=5)\n",
    "file.data_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot_encoding(folders):\n",
    "    names = []\n",
    "    for folder in folders:\n",
    "        names.append(folder[0].folder_name)\n",
    "    return pd.get_dummies(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_one_hot = get_one_hot_encoding(folders)\n",
    "dfi.export(names_one_hot, \"assets/table_5.png\")\n",
    "names_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all five actions into one dataframe and set the target labels \n",
    "iterator = 1\n",
    "all_df = []\n",
    "\n",
    "for folder in folders:    \n",
    "    # Create single dataframe for action\n",
    "    df = pd.DataFrame()\n",
    "    df = pd.concat([file.data_processed for file in folder])\n",
    "\n",
    "    # Add target labels\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "        df[\"Action\"] = iterator\n",
    "        iterator = iterator + 1\n",
    "    \n",
    "    # Add dataframe to the list\n",
    "    all_df.append(df)\n",
    "\n",
    "# Combine all dataframes into one\n",
    "df = pd.concat(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models\n",
    "\n",
    "Start by splitting the data into training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get csv data\n",
    "df = pd.read_csv('combined_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X = df.iloc[:, :-1]     # Input features\n",
    "y = df.iloc[:, -1:]     # Target labels\n",
    "\n",
    "# Split data into training (70%) and testing set (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The dimension of train is {}\".format(X_train.shape))\n",
    "print(\"The dimension of test is {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_count = pd.DataFrame()\n",
    "data_train = y_train['Action'].value_counts()\n",
    "data_test = y_test['Action'].value_counts()\n",
    "\n",
    "value_count = pd.concat([data_train, data_test], axis=1)\n",
    "value_count.insert(0, \"Action\", ['LGW', ' Ramp_ascend', 'Ramp_descend', 'Sit_to_stand', 'Stand_to_sit'], True)\n",
    "value_count = value_count.set_axis(['Action', 'Train Value Count', 'Test Value Count'], axis=1)\n",
    "value_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi.export(value_count, \"assets/table_6.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = ANN(X_train, X_test, y_train, y_test)\n",
    "ann.run_pipeline()\n",
    "ann.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVM(X_train, X_test, y_train, y_test)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    svm.run_pipeline()\n",
    "svm.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all five actions without any features extraction \n",
    "# into one dataframe and set the target labels\n",
    "iterator = 1\n",
    "all_df = []\n",
    "\n",
    "for folder in folders:    \n",
    "    # Create single dataframe for action\n",
    "    df_cnn = pd.DataFrame()\n",
    "    df_cnn = pd.concat([file.data_filtered for file in folder])\n",
    "\n",
    "    # Add target labels\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "        df_cnn[\"Action\"] = iterator\n",
    "        iterator = iterator + 1\n",
    "    \n",
    "    # Add dataframe to the list\n",
    "    all_df.append(df_cnn)\n",
    "\n",
    "# Combine all dataframes into one\n",
    "df_cnn = pd.concat(all_df)\n",
    "df_cnn.drop(columns=['Timestamp'], inplace=True)\n",
    "\n",
    "df_cnn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data CNN\n",
    "X_cnn = df_cnn.iloc[:, :-1]     # Input features\n",
    "y_cnn = df_cnn.iloc[:, -1:]     # Target labels\n",
    "\n",
    "# Split data into training (70%), validation (15%) and testing set (15%)\n",
    "X_train_cnn, X_test_cnn, y_train_cnn, y_test_cnn = train_test_split(X_cnn, y_cnn, test_size=0.3, random_state=109)\n",
    "X_val_cnn, X_test_cnn, y_val_cnn, y_test_cnn = train_test_split(X_test_cnn, y_test_cnn, test_size=0.5, random_state=109)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet19\n",
    "\n",
    "Generate a ResNet model inspired by: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9071921/ and adapt it for IMU data. Originally the network had 50 layers and was created for Electrocardiogram (ecg) automated diagnosis. In this scenario, the network was decreased to 19 layers (ResNet19) and the residuals layers were kept to 441 (take all sensor's data). Despite the succesfull formulation, the network is overparameterised, with multiple residual blocks of weights close to 0. To save on computation power, storage for the network and potential overfitting, a simple network was defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet19: Define dimensions\n",
    "nclasses = 6\n",
    "input_dims = (63, 1)  # Input dimensions\n",
    "residual_blocks_dims = [[63, 32],   # Output of conv layer       / Input of 1st residual blk\n",
    "                        [63, 128],  # Output of 1st residual blk / Input of 2st residual blk\n",
    "                        [63, 256]]  # Output of 2th residual blk / Input of dense layer\n",
    "\n",
    "# Get model\n",
    "model_resnet = ResNet1D(input_dims, residual_blocks_dims, nclasses)\n",
    "\n",
    "# Present model summary\n",
    "svg = plot_model(model_resnet, to_file='./assets/cnn_model_resnet.png', show_shapes=True, show_layer_names=True)\n",
    "model_resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization parameters\n",
    "lr = 0.1            # Learning rate\n",
    "epochs = 15         # Number of epochs\n",
    "batch_size = 64     # Batch size\n",
    "callbacks = []\n",
    "\n",
    "# Reduce learning rate on platteu; reduce the learning rate \n",
    "# when the validation loss stops improving. Addopted from\n",
    "# https://arxiv.org/abs/1711.05225.\n",
    "callbacks.append(ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                                   patience=10, min_lr=lr/10000))\n",
    "\n",
    "# Create file for tensorboard visualization, run:\n",
    "# $ tensorboard --logdir=./\n",
    "callbacks.append(TensorBoard(log_dir='./logs', write_graph=False))\n",
    "\n",
    "# Compile model\n",
    "model_resnet.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history_resnet = model_resnet.fit(X_train_cnn, y_train_cnn,\n",
    "                batch_size=batch_size, \n",
    "                epochs=epochs,\n",
    "                validation_data=(X_val_cnn, y_val_cnn), \n",
    "                callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model_resnet.evaluate(X_test_cnn, y_test_cnn, batch_size=64, verbose=1)\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize history for accuracy\n",
    "plt.plot(history_resnet.history['accuracy'])\n",
    "plt.plot(history_resnet.history['val_accuracy'])\n",
    "plt.title('ResNet1D CNN Model Accuracy', fontsize=20)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=16)\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()\n",
    "\n",
    "# Summarize history for loss\n",
    "plt.plot(history_resnet.history['loss'])\n",
    "plt.plot(history_resnet.history['val_loss'])\n",
    "plt.title('ResNet1D CNN Model Loss', fontsize=20)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=16)\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple model\n",
    "lr = 0.1                # Learning rate\n",
    "epochs = 10             # Number of epochs\n",
    "batch_size = 64         # Batch size\n",
    "nclasses = 6            # len(Output classes) + 1\n",
    "input_dims = (63, 1)   # Input dimensions\n",
    "callbacks = []\n",
    "\n",
    "# Reduce learning rate on platteu; reduce the learning rate \n",
    "# when the validation loss stops improving. Addopted from\n",
    "# https://arxiv.org/abs/1711.05225.\n",
    "callbacks.append(ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                                   patience=10, min_lr=lr/10000))\n",
    "\n",
    "# Create file for tensorboard visualization, run:\n",
    "# $ tensorboard --logdir=./\n",
    "callbacks.append(TensorBoard(log_dir='./logs', write_graph=False))\n",
    "\n",
    "# Get model\n",
    "model_simple = CNN(input_dims, nclasses)\n",
    "model_simple.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model_simple.fit(X_train_cnn, y_train_cnn, \n",
    "                 epochs=10, \n",
    "                 batch_size=32, \n",
    "                 validation_data=(X_val_cnn, y_val_cnn),\n",
    "                 callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svg = plot_model(model_simple, to_file='./assets/cnn_model_simple.png', show_shapes=True, show_layer_names=True)\n",
    "model_simple.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate simple model\n",
    "loss, accuracy = model_simple.evaluate(X_test_cnn, y_test_cnn, batch_size=32, verbose=1)\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Simple CNN Model Accuracy', fontsize=20)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=16)\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()\n",
    "\n",
    "# Summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Simple CNN Model Loss', fontsize=20)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=16)\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cnn = model_simple.predict(X_test_cnn)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "predicted_classes_cnn = np.argmax(y_pred_cnn, axis=1)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "labels = [label_map[i] for i in ann.model.classes_]\n",
    "plot_cm(y_test_cnn, predicted_classes_cnn, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the 15 most relevant weights for both ANN and SVG. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    ann_features, ann_scores = ann.get_most_relevant_features(X_train.columns,\n",
    "                                                                X_train.values,\n",
    "                                                                y_train.values)\n",
    "\n",
    "# Plot\n",
    "plt.barh(ann_features, ann_scores)\n",
    "plt.xlabel(\"Permutation Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    svm_features, svm_scores = svm.get_most_relevant_features(X_train.columns,\n",
    "                                                                X_train.values,\n",
    "                                                                y_train.values)\n",
    "\n",
    "# Plot \n",
    "plt.barh(svm_features, svm_scores)\n",
    "plt.xlabel(\"Permutation Importance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at correlation between high coefficinet features\n",
    "substrings = [\"Gyroscope\", \"Action\"]\n",
    "cols_to_keep = [col for col in df.columns if 'Gyroscope_X_max' in col or 'Action' in col]\n",
    "corr_df = df[cols_to_keep]\n",
    "heatmap = sns.heatmap(corr_df.corr(), vmin=-1, vmax=1, annot=True)\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at correlation between high coefficinet features\n",
    "plt.figure(figsize=(16, 6))\n",
    "substrings = [\"Gyroscope\", \"Action\"]\n",
    "cols_to_keep = [col for col in df.columns if 'Gyroscope_X_min' in col or 'Action' in col or 'Gyroscope_Y_min' in col]\n",
    "corr_df = df[cols_to_keep]\n",
    "heatmap = sns.heatmap(corr_df.corr(), vmin=-1, vmax=1, annot=True)\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the most significant segment which contributes to the activities recognition based on the ANN prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data based on the segment\n",
    "sensors = [\"Foot_L\", \"Foot_R\", \"Thigh_L\", \"Thigh_R\", \"Shank_L\", \"Shank_L\", \"Pelvis\"]\n",
    "sensors_data = {}\n",
    "\n",
    "# Get all columns that contain the sensor name\n",
    "for sensor in sensors:\n",
    "    columns = [col for col in df.columns if (sensor in col or \"Action\" in col)]\n",
    "    sensors_data[sensor] = df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print first sensor data\n",
    "first_entry = next(iter(sensors_data.values()))\n",
    "first_entry.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "# Get the accuracy of the ANN on each separate data\n",
    "for key, data in sensors_data.items():\n",
    "    # Split data\n",
    "    X = data.iloc[:, :-1]     # Input features\n",
    "    y = data.iloc[:, -1:]     # Target labels\n",
    "\n",
    "    # Split data into training (70%) and testing set (30%)\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.7, random_state=42)\n",
    "\n",
    "    # Create network and get accuracy\n",
    "    sensor_ann = ANN(X_tr, X_te, y_tr, y_te)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        sensor_ann.run_pipeline()\n",
    "        print(f'{key} accuracy : {sensor_ann.get_accuracy()}')\n",
    "\n",
    "    # Add model to the list\n",
    "    models.append(ModelToCompare(key , sensor_ann.get_accuracy(), sensor_ann, X_tr, X_te, y_tr, y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check highest accuacy\n",
    "max_acc_model = max(models, key=lambda item: item.accuracy) \n",
    "max_acc_model.model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using only the most relevant feature, calculate the clasification error using ANN\n",
    "print(f\"Classification error of the ANN using {max_acc_model.sensor}: {max_acc_model.model.get_classification_error()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = sensors_data[max_acc_model.sensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using only the most relevant feature, calculate the clasification error using SVM\n",
    "sensor = sensors_data[max_acc_model.sensor]\n",
    "\n",
    "# Split data\n",
    "X = sensor.iloc[:, :-1]     # Input features\n",
    "y = sensor.iloc[:, -1:]     # Target labels\n",
    "\n",
    "# Split data into training (70%) and testing set (30%)\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.7, random_state=42)\n",
    "\n",
    "max_svm_model = SVM(X_tr, X_te, y_tr, y_te)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    max_svm_model.run_pipeline()\n",
    "print(f\"Accuracy of the SVM using {max_acc_model.sensor}: {max_svm_model.get_accuracy()}\")\n",
    "print(f\"Classification error of the SVM using {max_acc_model.sensor}: {max_svm_model.get_classification_error()}\")\n",
    "max_svm_model.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
